from __future__ import absolute_import, division, print_function, unicode_literals

from os import path
from datetime import datetime

import hashlib
import os
import data
import tensorflow as tf
import numpy as np
import batching
import training
import pickle
from tflego import NP_DTYPE, TF_DTYPE, NP_ITYPE, TF_ITYPE
import tflego
from scipy.spatial.distance import cosine
from scipy.spatial.distance import cdist

from data import get_mfcc_dd
from pydub import AudioSegment
from progress.bar import Bar



def crop_audio(elt):
    # time = elt["whole"].index(elt["cost"]) * 30
    time = elt["time"]*1000
    deb = time - 0.5
    elt["code"] = len(os.listdir("./data/"))
    root = "/home/getalp/leferrae/corpora/mboshi-french-parallel-corpus/full_corpus_newsplit/all/"
    if deb<0:
        deb=0
    fin = time + elt["duree"]*100
    ext = AudioSegment.from_wav(root+elt['ref'])
    ext = ext[deb:fin]
    ext.export("./data/{}.wav".format(elt["code"]), format("wav"))
    sortie=get_mfcc_dd("./data/{}.wav".format(elt["code"]))
    return sortie

class Auto_encoder():

    def __init__(self, train, queries, corpus, data_dir, train_tag, max_length, min_length, rnn_type, enc_n_hiddens,
                 dec_n_hiddens, n_z, learning_rate, keep_prob, ae_n_epochs, ae_batch_size, ae_n_buckets, cae_n_epochs,
                 cae_batch_size, rnd_seed=1, bidirectional=False):
        self.train_d = train
        self.queries = queries
        self.corpus = corpus
        self.pair_list = []
        self.retrieved = {}
        self.pres_mot = {}
        self.precision = {}
        self.precision["TP"] = 0
        self.precision["TOT"] = 0
        self.save_html = []
        self.threshold = 0.1

        self.options_dict = {}
        self.options_dict["data_dir"] = data_dir
        self.options_dict["max_length"] = max_length
        self.options_dict["train_tag"] = train_tag
        self.options_dict["min_length"] = min_length
        self.options_dict["rnn_type"] = rnn_type
        self.options_dict["enc_n_hiddens"] = enc_n_hiddens
        self.options_dict["dec_n_hiddens"] = dec_n_hiddens
        self.options_dict["n_z"] = n_z
        self.options_dict["learning_rate"] = learning_rate
        self.options_dict["keep_prob"] = keep_prob
        self.options_dict["ae_n_epochs"] = ae_n_epochs
        self.options_dict["ae_batch_size"] = ae_batch_size
        self.options_dict["ae_n_buckets"] = ae_n_buckets
        self.options_dict["cae_n_epochs"] = cae_n_epochs
        self.options_dict["cae_batch_size"] = cae_batch_size
        self.options_dict["rnd_seed"] = rnd_seed
        self.options_dict["bidirectional"] = bidirectional

        hasher = hashlib.md5(repr(sorted(self.options_dict.items())).encode("ascii"))

        hash_str = hasher.hexdigest()[:10]
        self.model_dir = path.join(
            "models", path.split(self.options_dict["data_dir"])[-1] + "." +
                      self.options_dict["train_tag"], hash_str
        )
        self.options_dict_fn = path.join(self.model_dir, "self.options_dict.pkl")
        print("Model directory:", self.model_dir)
        if not os.path.isdir(self.model_dir):
            os.makedirs(self.model_dir)
        print("Options:", self.options_dict)

        # Random seeds
        np.random.seed(self.options_dict["rnd_seed"])
        # tf.set_random_seed(self.options_dict["rnd_seed"])
        tf.compat.v1.set_random_seed(self.options_dict["rnd_seed"])

    def make_model(self):

        d_frame = 13  # None
        self.options_dict["n_input"] = d_frame

        self.pretrain_intermediate_model_fn = path.join(self.model_dir, "ae.tmp.ckpt")
        self.pretrain_model_fn = path.join(self.model_dir, "ae.best_val.ckpt")
        self.intermediate_model_fn = path.join(self.model_dir, "cae.tmp.ckpt")
        self.model_fn = path.join(self.model_dir, "cae.best_val.ckpt")
        # Model graph

        self.a = tf.compat.v1.placeholder(TF_DTYPE, [None, None, self.options_dict["n_input"]])
        self.a_lengths = tf.compat.v1.placeholder(TF_ITYPE, [None])
        self.b = tf.compat.v1.placeholder(TF_DTYPE, [None, None, self.options_dict["n_input"]])
        self.b_lengths = tf.compat.v1.placeholder(TF_ITYPE, [None])
        self.network_dict = self.build_cae_from_options_dict(
            self.a, self.a_lengths, self.b_lengths, self.options_dict
        )
        mask = self.network_dict["mask"]
        self.z = self.network_dict["z"]

        y = self.network_dict["y"]

        # Reconstruction loss
        self.loss = tf.reduce_mean(
            tf.reduce_sum(tf.reduce_mean(tf.square(self.b - y), -1), -1) /
            tf.reduce_sum(mask, 1))

        self.optimizer = tf.train.AdamOptimizer(
            learning_rate=self.options_dict["learning_rate"]
        ).minimize(self.loss)


    def enc_queries(self, size_queries):#TODO rename function, the queries are not embedded

        queries = self.queries[: size_queries]
        train_tag = self.options_dict["train_tag"]
        min_length = None
        if self.options_dict["train_tag"] == "rnd":
            min_length = self.options_dict["min_length"]
            train_tag = "all"
        npz_fn = path.join(
            self.options_dict["data_dir"], "train." + train_tag + ".npz"
        )

        self.train_x, self.train_labels, train_lengths, train_keys = (
            data.load_data(self.train_d))
        self.quer_x, self.quer_label, self.quer_lengths, _ = (data.load_data(queries))

        # Truncate and limit dimensionality
        max_length = self.options_dict["max_length"]
        d_frame = self.options_dict["n_input"]
        print("Limiting dimensionality:", d_frame)
        print("Limiting length:", max_length)
        data.trunc_and_limit_dim(x=self.train_x, lengths=train_lengths, d_frame=d_frame, max_length=max_length)

        # Get pairs

        self.pair_list.append([(i,i) for i in range(0, len(queries))])

        self.train_ae(self.train_x)

    def build_cae_from_options_dict(self, a, a_lengths, b_lengths, options_dict):

        # Latent layer
        build_latent_func = tflego.build_autoencoder
        latent_func_kwargs = {
            "enc_n_hiddens": [],
            "n_z": options_dict["n_z"],
            "dec_n_hiddens": [options_dict["dec_n_hiddens"][0]],
            "activation": tf.nn.relu
        }


        # Network
        network_dict = tflego.build_multi_encdec_lazydynamic_latentfunc(
            a, a_lengths, options_dict["enc_n_hiddens"],
            options_dict["dec_n_hiddens"], build_latent_func, latent_func_kwargs,
            y_lengths=b_lengths, rnn_type=options_dict["rnn_type"],
            bidirectional=options_dict["bidirectional"],
            keep_prob=options_dict["keep_prob"],
            add_conditioning_tensor=None )

        encoder_states = network_dict["encoder_states"]
        ae = network_dict["latent_layer"]
        z = ae["z"]
        y = network_dict["decoder_output"]
        mask = network_dict["mask"]
        y *= tf.expand_dims(mask, -1)  # safety

        return {"z": z, "y": y, "mask": mask}

    def train_ae(self, train_x):

        self.val_model_fn = self.pretrain_intermediate_model_fn

        train_batch_iterator = batching.PairedBucketIterator(
            train_x, [(i, i) for i in range(len(train_x))],
            self.options_dict["ae_batch_size"], self.options_dict["ae_n_buckets"],
            shuffle_every_epoch=False, speaker_ids=None)

        self.session_conf = tf.ConfigProto(
            intra_op_parallelism_threads=2,
            inter_op_parallelism_threads=2)

        # ae_record_dict = training.train_fixed_epochs_external_val(
        #     self.options_dict["ae_n_epochs"], self.optimizer, self.loss, train_batch_iterator,
        #     [self.a, self.a_lengths, self.b, self.b_lengths],
        #     save_model_fn=self.pretrain_intermediate_model_fn,
        #     save_best_val_model_fn=self.pretrain_model_fn, config=self.session_conf
        # )
        #
        # record_dict_fn = path.join(self.model_dir, "record_dict.pkl")
        # print("Writing:", record_dict_fn)
        # with open(record_dict_fn, "wb") as f:
        #     pickle.dump(ae_record_dict, f, -1)
        #
        #
        # # Save options_dict
        # options_dict_fn = path.join(self.model_dir, "options_dict.pkl")
        # print("Writing:", options_dict_fn)
        # with open(options_dict_fn, "wb") as f:
        #     pickle.dump(self.options_dict, f, -1)

    def segment(self, corp, step=3, wind=[100, 70, 40]):
        """

        :param corp: corpus from which the segment are extracted
        :param step:
        :param wind: the lenghts of the differents segments extracted at a same time
        :return: a stack of embeded segments and a reference file
        """
        segs = []
        seg_ref = {}
        cpt = 0
        utt_lengths = []

        bar = Bar("Segmentation...", max=len(corp))
        for i, u in enumerate(corp):
            utt=u["data"]
            i_start = 0
            n_search = utt.shape[0]
            seg_list = []

            while i_start <= n_search - 1 or i_start == 0:
                for ind in wind:
                    sref = {}
                    sref["file"] = os.path.basename(u["file"])
                    sref["wind"] = ind
                    sref["time"] = i_start/100
                    seg_ref[cpt] = sref
                    seg=utt[i_start:i_start+ind]
                    utt_lengths.append(seg.shape[0])
                    i_start += step
                    cpt +=1
                    segs.append(seg)
            bar.next()
        bar.finish()

        data.trunc_and_limit_dim(x=segs, lengths=utt_lengths, d_frame=self.options_dict["n_input"],
                                 max_length=self.options_dict["max_length"])
        batch_iterator = batching.SimpleIterator(segs, 128, False)
        saver = tf.train.Saver()
        gups = len(tf.config.experimental.list_physical_devices('GPU'))


        with tf.Session() as session:
            saver.restore(session, self.charg)
            bar = Bar("Vectorization...", max = len(segs)//128)
            for batch_x_padded, batch_x_lengths in batch_iterator:
                np_x = batch_x_padded
                np_x_lengths = batch_x_lengths
                np_z = session.run(
                    [self.z], feed_dict={self.a: np_x, self.a_lengths: np_x_lengths}
                )[0]
                seg_list.append(np_z)
                bar.next()
            bar.finish()
        out=[]
        for x in seg_list:
            out.append([y for y in x])
        sent_emb = np.vstack(out)

        return sent_emb, seg_ref

    def do_dist(self, quota):
        data.trunc_and_limit_dim(x=self.quer_x, lengths=self.quer_lengths, d_frame=self.options_dict["n_input"],
                                 max_length=self.options_dict["max_length"])
        iterator = batching.SimpleIterator(self.quer_x, len(self.quer_x), False)
        saver = tf.train.Saver()
        temp = path.join(
            "models", path.split(self.options_dict["data_dir"])[-1] + "." +
                      self.options_dict["train_tag"], "4cb3a05a07")
        self.charg = path.join(temp, "ae.tmp.ckpt")

        with tf.Session() as session:

            # saver.restore(session, self.val_model_fn)
            saver.restore(session, self.charg)

            for batch_x_padded, batch_x_lengths in iterator:
                np_x = batch_x_padded
                np_x_lengths = batch_x_lengths
                emb_queries = session.run(
                    [self.z], feed_dict={self.a: np_x, self.a_lengths: np_x_lengths}
                )[0]
        embed_dict = {}

        for i, utt_key in enumerate(
                [self.train_labels[i] for i in iterator.indices]):
            embed_dict[utt_key] = emb_queries[i]

        # for z, w in enumerate(embed_dict):
        # self.retrieved[w] = []
        quers = np.vstack(emb_queries)
        with open("./lex_vecs.pkl", mode="wb") as pk_lex:
            pickle.dump(quers, pk_lex)
        print(datetime.now())
        segs, seg_ref = self.segment(self.corpus)
        print("distances")

        distances = cdist(segs, quers, metric="cosine")
        ret = []
        for i, seg in enumerate(distances):
            for j, partof in enumerate(seg):
                ret.append([partof, self.queries[j]["word"], i])
            # mn = np.min(seg)
            # w = np.where(seg == mn)
            # ind = (w[0][0])
            # ret.append([mn, self.queries[ind]["word"], i])
        meilleur = []
        verif = {}
        sort_ret = sorted(ret, key= lambda x : x[0])
        double = set()
        for j, m in enumerate(sort_ret):
            if m[1] not in verif:
                verif[m[1]] = 0
            if verif[m[1]] < quota:
                code = (seg_ref[m[2]]["time"], m[1] ,seg_ref[m[2]]["file"])
                if code not in double:
                    out = {}
                    out["dist"] = m[0]
                    out["word"] = m[1]
                    out["ref"] = seg_ref[m[2]]["file"]
                    out["time"] = seg_ref[m[2]]["time"]
                    out["duree"] = seg_ref[m[2]]["wind"]
                    meilleur.append(out)
                    verif[m[1]] += 1
                    double.add(code)

        print(datetime.now())
        # for i in meilleur:
        #     print(i["word"])
        #     with open("/home/leferrae/Desktop/These/mboshi/mboshi-french-parallel-corpus/full_corpus_newsplit/all/"+i["ref"].replace(".wav", ".mb")) as foo:
        #         print(foo.read())
        # print(meilleur)
        return meilleur

    def do_precision(self, max_inst, quota):
        meilleur = self.do_dist(quota)
        found = 0
        for can in meilleur:
            file_ref = "/home/leferrae/Desktop/These/mboshi/wrd/" + (os.path.basename(can["ref"])).replace(".wav", ".wrd")
            with open(file_ref, mode='r', encoding='utf-8') as op_ref:
                gold = op_ref.read()
            if can["word"] in gold:
                wrd = gold.split("\n")
                for line in wrd:
                    linesp = line.split()
                    if len(linesp) > 2:
                        if can["time"] > float(linesp[0]) - 0.5 and can["time"] < float(linesp[0]) + 0.5:
                            if can["word"] == linesp[2].lower():
                                found += 1
                                # found_m += 1
                                for inp in self.queries:
                                    if (can['word'] in inp["word"]) and (can['ref'] not in inp['ref']):
                                        if len(inp['ref']) < max_inst:
                                            inst = crop_audio(can)
                                            inp['data'].append(inst)
                                            inp['ref'].append(can['ref'])
                                            # self.save_html.append([can["word"], can["cost"], can["code"]])
        print("precision : {}%\t{}/{}".format(found/len(meilleur)*100, found, len(meilleur)))


        """
        bar = Bar("computing distances", max=len(embed_dict)*len(self.corpus))
        for z, w in enumerate(embed_dict):
            self.retrieved[w] = []
            for i, utt in enumerate(self.corpus):
                seg = self.segment(utt["data"])
                sub_seg = []
                for j, s in enumerate(seg):
                    dist = cosine(s, embed_dict[w])
                    
                    sub_seg.append(dist)
                best_sub = min(sub_seg)
                time = sub_seg.index(best_sub)//3
                fin = {}
                for i in self.queries:
                    if i["word"] == w:
                        fin["duree"] = i["duree"]
                fin["word"] = w
                fin["ref"] = utt["file"]
                fin["dist"] = best_sub
                fin['time'] = time
                fin["code"] = "u{}q{}".format(i, z)
                fin["checked"] = False
                self.retrieved[w].append(fin)
                bar.next()
        bar.finish()
        """

