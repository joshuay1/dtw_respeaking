{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total word count: 1748\n",
      "Unique word count: 94\n",
      "kabirri wanjh ngarri nan yiman kayime re kun wurdwurd bu bolbme warre ngurlken ngadberre kumekke ngad dabborrabbolk birri kunred ken yerre bedman kohbanj bolkki namekke nawu ngarrben wam but dja yolyolme njale djal ba karrme wali men kan rayinj ng manekke bukkan mak di nga kore ngan bolkkime manih meninj "
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords \n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "tokenizer = RegexpTokenizer(r'\\w+')\n",
    "from collections import Counter\n",
    "import Levenshtein as lev\n",
    "#from nltk.stem.snowball import SnowballStemmer\n",
    "#stemmer=SnowballStemmer(\"english\")\n",
    "\n",
    "\n",
    "f = open(\"interview-kunwok.txt\", \"r\")\n",
    "doc = f.read()\n",
    "print('Total word count: '+str(len(doc)))\n",
    "\n",
    "#stopwords = set(stopwords.words('english'))\n",
    "#additional_stopwords = ['i','mr','and', 'says', 'oh', 'never', 'take', 'whatever', 'might', 'say', 'non', 'well', 'get', 'like', 'know', 'think', 'much', 'could', 'said', 'really', 'actually', 'cannot', 'us', 'things']\n",
    "#new_stopwords = stopwords.union(additional_stopwords)\n",
    "\n",
    "tf = nltk.FreqDist(tokenizer.tokenize(doc))\n",
    "print('Unique word count: '+str(len(tf)))\n",
    "word_list = []\n",
    "\n",
    "for value, count in tf.most_common(100):\n",
    "    if count>1:\n",
    "        print(value, end=' ')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "import json\n",
    "with open('spoken_lex60.json') as jfile:\n",
    "    doc = json.load(jfile)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wanjh\n",
      "wurdurd\n",
      "kabirri-re\n",
      "manu\n",
      "kondah\n",
      "yiman\n",
      "kayime\n",
      "daluk\n",
      "kore\n",
      "kinga\n",
      "manekke\n",
      "namekke\n",
      "manme\n",
      "kabirri-nan\n",
      "kabirri-bolbme\n",
      "ngimeng\n",
      "nawu\n",
      "birri-wam\n",
      "njamed\n",
      "ngad\n",
      "ngadberre\n",
      "wurdwurd\n",
      "kunak\n",
      "kumekke\n",
      "ku-denge\n",
      "bi-kang\n",
      "ngalmekke\n",
      "borrhkeng\n",
      "kandji\n",
      "bedda\n",
      "karuy\n",
      "bolkkime\n",
      "niwirrinj\n",
      "dabborrabbolk\n",
      "bebhmeng\n",
      "minj\n",
      "man-berrk\n",
      "ngarrben-bukkan\n",
      "birri-yawam\n",
      "kun-dulk\n",
      "birri-kadjuy\n",
      "djenj\n",
      "bebmeng\n",
      "munguy\n",
      "ku-red\n",
      "kabirri-yime\n",
      "bininj\n",
      "bi-mey\n",
      "bi-kurrmeng\n",
      "birri-ni\n",
      "bushwalking\n",
      "birri-yoy\n",
      "nameh\n",
      "road\n",
      "bidbom\n",
      "dabuno\n",
      "kun-wale\n",
      "ngarri-re\n",
      "derek\n",
      "ku-ronj\n"
     ]
    }
   ],
   "source": [
    "i = 1 \n",
    "for word in doc:\n",
    "    file = open('word'+str(i)+'.txt','w')\n",
    "    file.write(word['kun'])\n",
    "    print(word['kun'])\n",
    "    file.close()\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
