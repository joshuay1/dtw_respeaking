{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Query-by-Example (QbE) Search Using DTW"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preliminary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "from os import path\n",
    "from python_speech_features import delta\n",
    "from python_speech_features import mfcc\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import scipy.io.wavfile as wav\n",
    "import sys\n",
    "import simpleaudio as sa\n",
    "from pydub import AudioSegment\n",
    "from pydub.playback import play\n",
    "from shennong.audio import Audio\n",
    "from shennong.features.processor.mfcc import MfccProcessor\n",
    "from shennong.features.postprocessor.delta import DeltaPostProcessor\n",
    "from shennong.features.processor.plp import PlpProcessor\n",
    "from shennong.features.postprocessor.cmvn import CmvnPostProcessor\n",
    "\n",
    "sys.path.append(\"..\")\n",
    "sys.path.append(path.join(\"..\", \"utils\"))\n",
    "\n",
    "from speech_dtw import qbe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mfcc_dd(wav_fn, cmvn=True):\n",
    "    \"\"\"Return the MFCCs with deltas and delta-deltas for a audio file.\"\"\"\n",
    "    audio = Audio.load(wav_fn)\n",
    "    processor = MfccProcessor(sample_rate=audio.sample_rate, window_type=\"hamming\",frame_length=0.025, frame_shift=0.01,\n",
    "                              cepstral_lifter=26.0,low_freq=0, vtln_low=60, vtln_high=7200, high_freq=audio.sample_rate/2)\n",
    "    d_processor = DeltaPostProcessor(order=2)\n",
    "    mfcc_static = processor.process(audio, vtln_warp=1.0)\n",
    "    mfcc_deltas = d_processor.process(mfcc_static)\n",
    "    features = np.float64(mfcc_deltas._to_dict()[\"data\"])\n",
    "\n",
    "    if cmvn:\n",
    "        features = (features - np.mean(features, axis=0)) / np.std(features, axis=0)\n",
    "    return features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Intermediate analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Align query to a search utterance from the same speaker containing the keyword."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Take Common English Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'DeltaPostProcessor' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-df02752d01c7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mrate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msignal\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwav\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwav_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mlength\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msignal\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mrate\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m1000\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0mquery_mfcc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_mfcc_dd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwav_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m     \u001b[0mquery\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m' '\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-10-1ae09308168a>\u001b[0m in \u001b[0;36mget_mfcc_dd\u001b[0;34m(wav_fn, cmvn)\u001b[0m\n\u001b[1;32m      4\u001b[0m     processor = MfccProcessor(sample_rate=audio.sample_rate, window_type=\"hamming\",frame_length=0.025, frame_shift=0.01,\n\u001b[1;32m      5\u001b[0m                               cepstral_lifter=26.0,low_freq=0, vtln_low=60, vtln_high=7200, high_freq=audio.sample_rate/2)\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0md_processor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDeltaPostProcessor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0mmfcc_static\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprocessor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maudio\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvtln_warp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1.0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mmfcc_deltas\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0md_processor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmfcc_static\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'DeltaPostProcessor' is not defined"
     ]
    }
   ],
   "source": [
    "import json# Grab spoken lexicon and return word, crop and duration of the word\n",
    "txt_file = open(\"english_words/common_words_100.txt\", \"r\")\n",
    "word_dict = txt_file.read().split(' ')\n",
    "common_word_list = []\n",
    "i = 0\n",
    "for wav_fn in sorted(glob.glob(path.join(\"english_words/common\", \"common_word_??.wav\"))):\n",
    "    rate, signal = wav.read(wav_fn)\n",
    "    length = len(signal) / rate * 1000\n",
    "    query_mfcc = get_mfcc_dd(wav_fn)\n",
    "    query = {}\n",
    "    print(word_dict[i], end=' ')\n",
    "    query[\"length\"] = length\n",
    "    query[\"data\"] = query_mfcc\n",
    "    query[\"word\"] = word_dict[i]\n",
    "    query[\"audio\"] = AudioSegment.from_file(wav_fn, format=\"wav\")\n",
    "    query[\"thres\"] = 1\n",
    "    #play(query[\"audio\"])\n",
    "    common_word_list.append(query)\n",
    "    i+=1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(common_word_list[99][\"word\"])\n",
    "play(common_word_list[99][\"audio\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rudd_original_mfcc_list = []\n",
    "rudd_original_wav = []\n",
    "for wav_fn in sorted(glob.glob(path.join(\"utterances\", \"rudd-apology_?.wav\"))):\n",
    "    print(\"Reading:\", wav_fn)\n",
    "    #original_wav.append(sa.WaveObject.from_wave_file(wav_fn))\n",
    "    rudd_original_wav.append(AudioSegment.from_file(wav_fn, format=\"wav\"))\n",
    "    rudd_original_mfcc_list.append(get_mfcc_dd(wav_fn))\n",
    "    \n",
    "for wav_fn in sorted(glob.glob(path.join(\"utterances\", \"rudd-apology_??.wav\"))):\n",
    "    print(\"Reading:\", wav_fn)\n",
    "    #original_wav.append(sa.WaveObject.from_wave_file(wav_fn))\n",
    "    rudd_original_wav.append(AudioSegment.from_file(wav_fn, format=\"wav\"))\n",
    "    rudd_original_mfcc_list.append(get_mfcc_dd(wav_fn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sweep_original = qbe.dtw_sweep(common_word_list[0]['data'], rudd_original_mfcc_list[0])\n",
    "plt.plot(sweep_original,color='green')\n",
    "play(common_word_list[0]['audio'])\n",
    "play(rudd_original_wav[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
